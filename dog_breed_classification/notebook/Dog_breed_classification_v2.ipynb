{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dog breed classification via ResNet-50 transfer learning version 2\n",
    "\n",
    "Tutorial for dog breed classification via ResNet-50 transfer learning in pytorch by using the dataset stored in the home directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change directory\n",
    "notebook_id = %env TRAINING_NOTEBOOK_ID\n",
    "%cd '/mnt/notebooks/{notebook_id}/Platform_handson/dog_breed_classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data in /home/data\n",
    "!wget http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar -P /home/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract tar file\n",
    "n_files = !tar tf /home/data/images.tar | grep .jpg | wc -l\n",
    "!tar xvf /home/data/images.tar -C /home/data/ | pv -l -s {n_files[0]} > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "from glob import glob             \n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Vasualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load filenames for dog images\n",
    "dog_files = list(glob(\"/home/data/Images/*/*\"))\n",
    "\n",
    "# print number of images in dataset\n",
    "print('There are %d total dog images.' % len(dog_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor(img):\n",
    "    '''\n",
    "    As per Pytorch documentations: All pre-trained models expect input images normalized in the same way, \n",
    "    i.e. mini-batches of 3-channel RGB images\n",
    "    of shape (3 x H x W), where H and W are expected to be at least 224. \n",
    "    The images have to be loaded in to a range of [0, 1] and \n",
    "    then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. \n",
    "    '''\n",
    "    img = img.convert('RGB')\n",
    "    transformations = transforms.Compose([transforms.Resize(size=224),\n",
    "                                          transforms.CenterCrop((224,224)),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                              std=[0.229, 0.224, 0.225])])\n",
    "    image_tensor = transformations(img)[:3,:,:].unsqueeze(0)\n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "# helper function for un-normalizing an image\n",
    "# and converting it from a Tensor image to a NumPy image for display\n",
    "def im_convert(tensor):\n",
    "    \"\"\" Display a tensor as an image. \"\"\"\n",
    "    \n",
    "    image = tensor.to(\"cpu\").clone().detach()\n",
    "    image = image.numpy().squeeze()\n",
    "    image = image.transpose(1,2,0)\n",
    "    image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n",
    "    image = image.clip(0, 1)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show one of images\n",
    "dog_image = Image.open('/home/data/Images/n02085620-Chihuahua/n02085620_431.jpg')\n",
    "plt.imshow(dog_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show one of images after conversion\n",
    "test_tensor = image_to_tensor(dog_image)\n",
    "print(test_tensor.shape)\n",
    "plt.imshow(im_convert(test_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and validation data directories\n",
    "data_dir = '/home/data/Images/'\n",
    "\n",
    "# how many samples per batch to load\n",
    "batch_size = 16\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 2\n",
    "\n",
    "# difine size of validation data\n",
    "valid_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to a normalized torch.FloatTensor\n",
    "train_transform = transforms.Compose([transforms.Resize(size=224),\n",
    "                                transforms.CenterCrop((224,224)),\n",
    "                                transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
    "                                transforms.RandomRotation(10),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "valid_transform = transforms.Compose([transforms.Resize(size=224),\n",
    "                                transforms.CenterCrop((224,224)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_train_test(data_dir, valid_size, batch_size, num_workers):\n",
    "    \"\"\" Split dataset into train and validation set \"\"\"\n",
    "    \n",
    "    train_data = datasets.ImageFolder(data_dir,       \n",
    "                    transform=train_transform)\n",
    "    valid_data = datasets.ImageFolder(data_dir,\n",
    "                    transform=valid_transform)\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    \n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=batch_size, num_workers=num_workers)\n",
    "    validloader = torch.utils.data.DataLoader(valid_data,\n",
    "                   sampler=valid_sampler, batch_size=batch_size, num_workers=num_workers)\n",
    "    \n",
    "    return trainloader, validloader\n",
    "\n",
    "trainloader, validloader = load_split_train_test(data_dir, valid_size, batch_size, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_names = trainloader.dataset.classes\n",
    "nb_classes = len(class_names)\n",
    "\n",
    "print(\"Number of classes:\", nb_classes)\n",
    "print(\"\\nClass names: \\n\\n\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(trainloader))\n",
    "\n",
    "for image, label in zip(inputs, classes): \n",
    "    image = image.to(\"cpu\").clone().detach()\n",
    "    image = image.numpy().squeeze()\n",
    "    image = image.transpose(1,2,0)\n",
    "    image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n",
    "    image = image.clip(0, 1)\n",
    "     \n",
    "    fig = plt.figure(figsize=(12,3))\n",
    "    plt.imshow(image)\n",
    "    plt.title(class_names[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify model architecture (ResNet-50)\n",
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# replace the last fully connected layer with a Linnear layer with 120 out features\n",
    "model.fc = nn.Linear(2048, 120)\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, trainloader, validloader, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = 3.877533 #np.Inf\n",
    "    \n",
    "    if os.path.exists(save_path):\n",
    "        model.load_state_dict(torch.load(save_path))\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training, validation loss and validation accuracy\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        \n",
    "        # train the model\n",
    "        model.train()\n",
    "        for data, target in trainloader:\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        # validate the model\n",
    "        model.eval()\n",
    "        for data, target in validloader:\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update average validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            # count number of correct labels\n",
    "            _, preds_tensor = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (preds_tensor == target).sum().item()\n",
    "            \n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(trainloader.dataset)\n",
    "        valid_loss = valid_loss/len(validloader.dataset)\n",
    "        # calculate accuracy\n",
    "        valid_accuracy = correct/total\n",
    "        \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tValidation accuracy: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            valid_accuracy\n",
    "            ))\n",
    "        \n",
    "        # save model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "n_epochs = 5\n",
    "train(n_epochs, trainloader, validloader, model, optimizer, criterion, use_cuda, './model/dog_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# load the model for CPU\n",
    "device = torch.device('cpu')\n",
    "dog_model = models.resnet50(pretrained=True)\n",
    "\n",
    "# freeze parameters so we don't backprop through them\n",
    "for param in dog_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# replace the last fully connected layer with a Linnear layer with 120 out features\n",
    "dog_model.fc = nn.Linear(2048, 120)\n",
    "\n",
    "dog_model.load_state_dict(torch.load('./model/dog_model.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor(img):\n",
    "    '''\n",
    "    As per Pytorch documentations: All pre-trained models expect input images normalized in the same way, \n",
    "    i.e. mini-batches of 3-channel RGB images\n",
    "    of shape (3 x H x W), where H and W are expected to be at least 224. \n",
    "    The images have to be loaded in to a range of [0, 1] and \n",
    "    then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. \n",
    "    '''\n",
    "    img = img.convert('RGB')\n",
    "    transformations = transforms.Compose([transforms.Resize(size=224),\n",
    "                                          transforms.CenterCrop((224,224)),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                              std=[0.229, 0.224, 0.225])])\n",
    "    image_tensor = transformations(img)[:3,:,:].unsqueeze(0)\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of class names\n",
    "class_names = ['CHIHUAHUA',\n",
    " 'JAPANESE SPANIEL',\n",
    " 'MALTESE DOG',\n",
    " 'PEKINESE',\n",
    " 'SHIH-TZU',\n",
    " 'BLENHEIM SPANIEL',\n",
    " 'PAPILLON',\n",
    " 'TOY TERRIER',\n",
    " 'RHODESIAN RIDGEBACK',\n",
    " 'AFGHAN HOUND',\n",
    " 'BASSET',\n",
    " 'BEAGLE',\n",
    " 'BLOODHOUND',\n",
    " 'BLUETICK',\n",
    " 'BLACK-AND-TAN COONHOUND',\n",
    " 'WALKER HOUND',\n",
    " 'ENGLISH FOXHOUND',\n",
    " 'REDBONE',\n",
    " 'BORZOI',\n",
    " 'IRISH WOLFHOUND',\n",
    " 'ITALIAN GREYHOUND',\n",
    " 'WHIPPET',\n",
    " 'IBIZAN HOUND',\n",
    " 'NORWEGIAN ELKHOUND',\n",
    " 'OTTERHOUND',\n",
    " 'SALUKI',\n",
    " 'SCOTTISH DEERHOUND',\n",
    " 'WEIMARANER',\n",
    " 'STAFFORDSHIRE BULLTERRIER',\n",
    " 'AMERICAN STAFFORDSHIRE TERRIER',\n",
    " 'BEDLINGTON TERRIER',\n",
    " 'BORDER TERRIER',\n",
    " 'KERRY BLUE TERRIER',\n",
    " 'IRISH TERRIER',\n",
    " 'NORFOLK TERRIER',\n",
    " 'NORWICH TERRIER',\n",
    " 'YORKSHIRE TERRIER',\n",
    " 'WIRE-HAIRED FOX TERRIER',\n",
    " 'LAKELAND TERRIER',\n",
    " 'SEALYHAM TERRIER',\n",
    " 'AIREDALE',\n",
    " 'CAIRN',\n",
    " 'AUSTRALIAN TERRIER',\n",
    " 'DANDIE DINMONT',\n",
    " 'BOSTON BULL',\n",
    " 'MINIATURE SCHNAUZER',\n",
    " 'GIANT SCHNAUZER',\n",
    " 'STANDARD SCHNAUZER',\n",
    " 'SCOTCH TERRIER',\n",
    " 'TIBETAN TERRIER',\n",
    " 'SILKY TERRIER',\n",
    " 'SOFT-COATED WHEATEN TERRIER',\n",
    " 'WEST HIGHLAND WHITE TERRIER',\n",
    " 'LHASA',\n",
    " 'FLAT-COATED RETRIEVER',\n",
    " 'CURLY-COATED RETRIEVER',\n",
    " 'GOLDEN RETRIEVER',\n",
    " 'LABRADOR RETRIEVER',\n",
    " 'CHESAPEAKE BAY RETRIEVER',\n",
    " 'GERMAN SHORT-HAIRED POINTER',\n",
    " 'VIZSLA',\n",
    " 'ENGLISH SETTER',\n",
    " 'IRISH SETTER',\n",
    " 'GORDON SETTER',\n",
    " 'BRITTANY SPANIEL',\n",
    " 'CLUMBER',\n",
    " 'ENGLISH SPRINGER',\n",
    " 'WELSH SPRINGER SPANIEL',\n",
    " 'COCKER SPANIEL',\n",
    " 'SUSSEX SPANIEL',\n",
    " 'IRISH WATER SPANIEL',\n",
    " 'KUVASZ',\n",
    " 'SCHIPPERKE',\n",
    " 'GROENENDAEL',\n",
    " 'MALINOIS',\n",
    " 'BRIARD',\n",
    " 'KELPIE',\n",
    " 'KOMONDOR',\n",
    " 'OLD ENGLISH SHEEPDOG',\n",
    " 'SHETLAND SHEEPDOG',\n",
    " 'COLLIE',\n",
    " 'BORDER COLLIE',\n",
    " 'BOUVIER DES FLANDRES',\n",
    " 'ROTTWEILER',\n",
    " 'GERMAN SHEPHERD',\n",
    " 'DOBERMAN',\n",
    " 'MINIATURE PINSCHER',\n",
    " 'GREATER SWISS MOUNTAIN DOG',\n",
    " 'BERNESE MOUNTAIN DOG',\n",
    " 'APPENZELLER',\n",
    " 'ENTLEBUCHER',\n",
    " 'BOXER',\n",
    " 'BULL MASTIFF',\n",
    " 'TIBETAN MASTIFF',\n",
    " 'FRENCH BULLDOG',\n",
    " 'GREAT DANE',\n",
    " 'SAINT BERNARD',\n",
    " 'ESKIMO DOG',\n",
    " 'MALAMUTE',\n",
    " 'SIBERIAN HUSKY',\n",
    " 'AFFENPINSCHER',\n",
    " 'BASENJI',\n",
    " 'PUG',\n",
    " 'LEONBERG',\n",
    " 'NEWFOUNDLAND',\n",
    " 'GREAT PYRENEES',\n",
    " 'SAMOYED',\n",
    " 'POMERANIAN',\n",
    " 'CHOW',\n",
    " 'KEESHOND',\n",
    " 'BRABANCON GRIFFON',\n",
    " 'PEMBROKE',\n",
    " 'CARDIGAN',\n",
    " 'TOY POODLE',\n",
    " 'MINIATURE POODLE',\n",
    " 'STANDARD POODLE',\n",
    " 'MEXICAN HAIRLESS',\n",
    " 'DINGO',\n",
    " 'DHOLE',\n",
    " 'AFRICAN HUNTING DOG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_breed(img, use_cuda=False):\n",
    "    \"\"\" load the image and return the predicted breed \"\"\"\n",
    "    image_tensor = image_to_tensor(img)\n",
    "    \n",
    "    # get outputs\n",
    "    if use_cuda:\n",
    "        image_tensor = image_tensor.cuda()\n",
    "    \n",
    "    dog_model.eval()\n",
    "    output = dog_model(image_tensor)\n",
    "    \n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    pred = np.squeeze(preds_tensor.numpy()) if not use_cuda else np.squeeze(preds_tensor.cpu().numpy())\n",
    "    result = class_names[pred]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def display_image(img, title=\"Title\"):\n",
    "    plt.title(title)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "def dog_classifier(img):\n",
    "    predicted_breed = predict_breed(img)\n",
    "    display_image(img, title=f\"Predicted:{predicted_breed}\")\n",
    "        \n",
    "    print(\"Your breed is most likley ...\")\n",
    "    print(predicted_breed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline\n",
    "\n",
    "img = Image.open('./sample/test_french_bull.jpg')\n",
    "dog_classifier(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('./sample/test_bull_mastif.jpg')\n",
    "dog_classifier(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
