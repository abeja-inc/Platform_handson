{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ABEJA Platform dataset\n",
    "\n",
    "Tutorial for creating ABEJA Platform dataset from online data source  \n",
    "Sample code uses Stanford Dogs Dataset: http://vision.stanford.edu/aditya86/ImageNetDogs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data in /home/data\n",
    "!wget http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar -P /home/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract tar file\n",
    "n_files = !tar tf /home/data/images.tar | grep .jpg | wc -l\n",
    "!tar xvf /home/data/images.tar -C /home/data/ | pv -l -s {n_files[0]} > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "# load filenames for images\n",
    "test_files = list(glob('/home/data/Images/*/*'))\n",
    "test_dir = list(glob('/home/data/Images/*'))\n",
    "\n",
    "# print number of images in dataset\n",
    "print('There are %d total images.' % len(test_files))\n",
    "test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load filenames for selected images\n",
    "selected = ['French_bulldog', 'Chihuahua','bull_mastiff',\n",
    "          'Labrador_retriever', 'Boston_bull']\n",
    "\n",
    "selected_files = []\n",
    "\n",
    "for file in test_files:\n",
    "    for item in selected:\n",
    "        if item in file:\n",
    "            selected_files.append(file)\n",
    "\n",
    "# print number of images in dataset\n",
    "print('There are %d selected images.' % len(selected_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show one of images\n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline         \n",
    "from PIL import Image, ImageFile \n",
    "\n",
    "image = Image.open(selected_files[0])\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create Datalake channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abeja.datalake import Client as DatalakeClient\n",
    "from abeja.datalake.storage_type import StorageType\n",
    "\n",
    "datalake_client = DatalakeClient()\n",
    "\n",
    "# define your own name and description\n",
    "name = 'XXXXX'\n",
    "description = 'XXXXX'\n",
    "\n",
    "channel = datalake_client.channels.create(name, description, StorageType.DATALAKE.value)\n",
    "channel_id = channel.channel_id\n",
    "    \n",
    "print('channel_id is %s.' % channel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# upload home directory data to datalake\n",
    "for file in tqdm(selected_files):\n",
    "    dir_name = os.path.basename(os.path.dirname(file))\n",
    "    dir_name = os.path.basename(dir_name) # get directory name for labeling\n",
    "    dir_name = dir_name.upper() # conver to uppercase \n",
    "    label_name = dir_name[10:] # remove numbers\n",
    "    metadata = {'label': label_name}\n",
    "    file = channel.upload_file(file, metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create dataset label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = sorted([item.upper() for item in selected])\n",
    "    \n",
    "print('No. of categories is %d.' % len(categories))\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset label from category names\n",
    "labels = []\n",
    "label_to_id = {}\n",
    "\n",
    "for i, name in enumerate(categories):\n",
    "    label_to_id[name] = i\n",
    "    labels.append({'label_id': i,\n",
    "                   'label': name})\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset name\n",
    "dataset_name = 'XXXXX'\n",
    "\n",
    "# create dataset label\n",
    "category = {\n",
    "    'category_id': 0,\n",
    "    'name': dataset_name,\n",
    "    'labels': labels}\n",
    "\n",
    "props = {'categories': [category]}\n",
    "props"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create Dataset from Datalake channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abeja.datasets import Client as DatasetClient\n",
    "\n",
    "dataset_client = DatasetClient()\n",
    "\n",
    "# create dataset\n",
    "dataset = dataset_client.datasets.create(name=dataset_name, type='classification', props=props)\n",
    "dataset_id = dataset.dataset_id\n",
    "\n",
    "print('dataset_id is %s.' % dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# delete dataset\n",
    "#dataset_client.datasets.delete(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset by importing datlake data\n",
    "\n",
    "for f in tqdm(channel.list_files()):\n",
    "    data_uri = f.uri\n",
    "    filename = f.metadata['filename']\n",
    "    label = f.metadata['label']\n",
    "    label_id = label_to_id[label]\n",
    "    \n",
    "    if os.path.splitext(filename)[1].lower() == '.jpg' or \\\n",
    "    os.path.splitext(filename)[1].lower() == '.jpeg':\n",
    "        content_type = 'image/jpeg'\n",
    "    elif os.path.splitext(filename)[1].lower() == '.png':\n",
    "        content_type = 'image/png'\n",
    "    else:\n",
    "        print('{} is invalid file type.'.format(filename))\n",
    "        continue\n",
    "    \n",
    "    source_data = [{'data_uri': data_uri, 'data_type': content_type}]\n",
    "    attributes = {'classification': [{'category_id': 0, 'label_id': label_id, 'label': label}]}\n",
    "\n",
    "    dataset.dataset_items.create(source_data, attributes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
