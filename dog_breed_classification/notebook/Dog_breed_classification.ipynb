{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dog breed classification via ResNet-50 transfer learning\n",
    "\n",
    "Tutorial for dog breed classification via ResNet-50 transfer learning in pytorch by using the dataset imported from ABEJA Platform Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import random\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline\n",
    "\n",
    "from abeja.datasets import Client\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Import data from ABEJA Platform Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change directory\n",
    "notebook_id = %env TRAINING_NOTEBOOK_ID\n",
    "%cd '/mnt/notebooks/{notebook_id}/Platform_handson/dog_breed_classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset id\n",
    "dataset_id = 'XXXXXXXXXXXXX'\n",
    "client = Client()\n",
    "dataset = client.get_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from ABEJA Platform Dataset\n",
    "dataset_list = list(dataset.dataset_items.list(prefetch=False))\n",
    "               \n",
    "dataset_list_img_label = []\n",
    "\n",
    "for item in tqdm(dataset_list):\n",
    "    # get data and label_id\n",
    "    file_content = item.source_data[0].get_content()\n",
    "    file_like_object = io.BytesIO(file_content)\n",
    "    img = Image.open(file_like_object)\n",
    "    img = img.convert('RGB')\n",
    "    dataset_list_img_label.append([img, item.attributes['classification'][0]['label_id']])\n",
    "\n",
    "# print number of images in dataset\n",
    "print('There are %d total images.' % len(dataset_list_img_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show one of images\n",
    "image = dataset_list_img_label[0][0]\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "print('label_id is %d' % dataset_list_img_label[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show dataset properties\n",
    "dataset.props['categories'][0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of label id and label name\n",
    "id_to_label = {}\n",
    "labels = []\n",
    "for item in dataset.props['categories'][0]['labels']:\n",
    "    id_to_label[item['label_id']] = item['label']\n",
    "    labels.append(item['label'].upper())\n",
    "    \n",
    "num_classes = len(id_to_label)\n",
    "\n",
    "print(\"Number of classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your dataset class\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, dataset_list_img_label, transform=None):\n",
    "        self.transform = transform\n",
    "        self.dataset_list_img_label = dataset_list_img_label\n",
    "        self.img = []\n",
    "        self.label = []\n",
    "        for item in dataset_list_img_label:\n",
    "            self.img.append(item[0])\n",
    "            self.label.append(item[1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_img = self.img[idx]\n",
    "        out_label =  self.label[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            out_img = self.transform(out_img)\n",
    "        \n",
    "        return out_img, out_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many samples per batch to load\n",
    "batch_size = 12\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 1\n",
    "\n",
    "# define size of validation data\n",
    "valid_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to a normalized torch.FloatTensor\n",
    "train_transform = transforms.Compose([transforms.Resize(size=224),\n",
    "                                transforms.CenterCrop((224,224)),\n",
    "                                transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
    "                                transforms.RandomRotation(10),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "valid_transform = transforms.Compose([transforms.Resize(size=224),\n",
    "                                transforms.CenterCrop((224,224)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_split_train_test(dataset_list_img_label, valid_size, batch_size):\n",
    "    \"\"\" Split dataset into train and validation set \"\"\"\n",
    "    \n",
    "    train_data = Dataset(dataset_list_img_label, transform=train_transform)\n",
    "    valid_data = Dataset(dataset_list_img_label, transform=valid_transform)\n",
    "    \n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    \n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=batch_size, num_workers=num_workers)\n",
    "    validloader = torch.utils.data.DataLoader(valid_data,\n",
    "                   sampler=valid_sampler, batch_size=batch_size, num_workers=num_workers)\n",
    "    \n",
    "    return trainloader, validloader\n",
    "\n",
    "trainloader, validloader = load_split_train_test(dataset_list_img_label, valid_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a batch of training data\n",
    "inputs, classes = next(iter(trainloader))\n",
    "\n",
    "for image, label in zip(inputs, classes): \n",
    "    image = image.to(\"cpu\").clone().detach()\n",
    "    image = image.numpy().squeeze()\n",
    "    image = image.transpose(1,2,0)\n",
    "    image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n",
    "    image = image.clip(0, 1)\n",
    "     \n",
    "    fig = plt.figure(figsize=(12,3))\n",
    "    plt.imshow(image)\n",
    "    plt.title(id_to_label[label.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify model architecture (ResNet-50)\n",
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# replace the last fully connected layer with a Linnear layer with no. of classes out features\n",
    "model.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, trainloader, validloader, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = 3.877533 #np.Inf\n",
    "    \n",
    "    if os.path.exists(save_path):\n",
    "        model.load_state_dict(torch.load(save_path))\n",
    "   \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training, validation loss and validation accuracy\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        \n",
    "        # train the model\n",
    "        model.train()\n",
    "        for data, target in tqdm(trainloader):\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        # validate the model\n",
    "        model.eval()\n",
    "        for data, target in tqdm(validloader):\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update average validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            # count number of correct labels\n",
    "            _, preds_tensor = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (preds_tensor == target).sum().item()\n",
    "            \n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(trainloader.dataset)\n",
    "        valid_loss = valid_loss/len(validloader.dataset)\n",
    "        # calculate accuracy\n",
    "        valid_accuracy = correct/total\n",
    "        \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tValidation accuracy: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            valid_accuracy\n",
    "            ))\n",
    "        \n",
    "        # save model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "n_epochs = 5\n",
    "model_train = train(n_epochs, trainloader, validloader, model, optimizer, criterion, use_cuda, './model/dog_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of class names\n",
    "class_names = ['BOSTON_BULL',\n",
    "               'BULL_MASTIFF',\n",
    "               'CHIHUAHUA',\n",
    "               'FRENCH_BULLDOG',\n",
    "               'LABRADOR_RETRIEVER']\n",
    "\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model for CPU\n",
    "device = torch.device('cpu')\n",
    "model_test = models.resnet50(pretrained=True)\n",
    "\n",
    "# freeze parameters so we don't backprop through them\n",
    "for param in model_test.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# replace the last fully connected layer with a Linnear layer with 120 out features\n",
    "model_test.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "model_test.load_state_dict(torch.load('./model/dog_model.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor(img):\n",
    "    '''\n",
    "    As per Pytorch documentations: All pre-trained models expect input images normalized in the same way, \n",
    "    i.e. mini-batches of 3-channel RGB images\n",
    "    of shape (3 x H x W), where H and W are expected to be at least 224. \n",
    "    The images have to be loaded in to a range of [0, 1] and \n",
    "    then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. \n",
    "    '''\n",
    "    img = img.convert('RGB')\n",
    "    transformations = transforms.Compose([transforms.Resize(size=224),\n",
    "                                          transforms.CenterCrop((224,224)),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                              std=[0.229, 0.224, 0.225])])\n",
    "    image_tensor = transformations(img)[:3,:,:].unsqueeze(0)\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img, use_cuda=False):\n",
    "    \"\"\" load the image and return the predicted breed \"\"\"\n",
    "    image_tensor = image_to_tensor(img)\n",
    "    \n",
    "    # get outputs\n",
    "    if use_cuda:\n",
    "        image_tensor = image_tensor.cuda()\n",
    "    \n",
    "    model_test.eval()\n",
    "    output = model_test(image_tensor)\n",
    "    \n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    pred = np.squeeze(preds_tensor.numpy()) if not use_cuda else np.squeeze(preds_tensor.cpu().numpy())\n",
    "    result = class_names[pred]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def display_image(img, title=\"Title\"):\n",
    "    plt.title(title)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "def classifier(img):\n",
    "    predicted = predict(img)\n",
    "    display_image(img, title=f\"Predicted:{predicted}\")\n",
    "        \n",
    "    print(\"It is most likley ...\")\n",
    "    print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline\n",
    "\n",
    "img = Image.open('./sample/test_french_bull.jpg')\n",
    "classifier(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = Image.open('./sample/test_bull_mastif.jpg')\n",
    "classifier(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('./sample/test_Labrador.jpg')\n",
    "classifier(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
