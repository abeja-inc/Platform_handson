{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comments Classification\n",
    "\n",
    "This is a sample notebook working with the data sets in https://figshare.com/articles/Wikipedia_Talk_Labels_Toxicity/4563973"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Load data from Datalake channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from abeja.datalake import Client as DatalakeClient\n",
    "\n",
    "# set channel id\n",
    "channel_id = 'XXXXXXXXXXXXX'\n",
    "\n",
    "# set file name\n",
    "data_file_name = 'toxicity_annotated_comments.tsv'\n",
    "annotation_file_name = 'toxicity_annotations.tsv'\n",
    "\n",
    "\n",
    "def load_file_from_datalake(channel_id, file_name):\n",
    "    datalake_client = DatalakeClient()\n",
    "    channel = datalake_client.get_channel(channel_id)\n",
    "\n",
    "    # load file\n",
    "    for f in channel.list_files():\n",
    "        if f.metadata['filename'] == file_name:\n",
    "            file_path = f.download_url\n",
    "            print('load ' + file_name)\n",
    "            return file_path\n",
    "\n",
    "        \n",
    "data_file = load_file_from_datalake(channel_id, data_file_name)\n",
    "annotation_file = load_file_from_datalake(channel_id, annotation_file_name)\n",
    "\n",
    "data = pd.read_csv(data_file, sep='\\t', index_col=0)\n",
    "annotation =  pd.read_csv(annotation_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check raw data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check annotaion\n",
    "annotation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels a comment as \"toxic\" if the majority of annoatators did so\n",
    "labels = annotation.groupby('rev_id')['toxicity'].mean() > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join labels and comments\n",
    "data['toxic'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unneccesary words (newline and tab tokens)\n",
    "data['comment'] = data['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "data['comment'] = data['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cleaned data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show \"toxic\" comments \n",
    "print(\"No of toxic comment: {}\".format(len(data[data['toxic'] == True])))\n",
    "print(\"No of non-toxic comment: {}\".format(len(data[data['toxic'] == False])))\n",
    "print(\"\\n--- sample of toxic comment ---\")\n",
    "data[data['toxic'] == True]['comment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in dataset\n",
    "null_check = data.isnull().sum()\n",
    "null_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Combine all comments for the desired sentiment\n",
    "toxic_comments = data[data['toxic'] == False]['comment'].values\n",
    "combined_text = \" \".join([x for x in toxic_comments])\n",
    "\n",
    "# Initialize wordcloud object\n",
    "wc = WordCloud(background_color='white', max_words=50, collocations=False)\n",
    "\n",
    "# Generate and plot wordcloud\n",
    "plt.imshow(wc.generate(combined_text))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test, dev dataset \n",
    "X_train = data[data['split']=='train']['comment'].values\n",
    "X_test = data[data['split']=='test']['comment'].values\n",
    "# X_dev = data[data['split']=='dev']['comment'].values\n",
    "Y_train = data[data['split']=='train']['toxic'].values\n",
    "Y_test = data[data['split']=='test']['toxic'].values\n",
    "# Y_dev = data[data['split']=='dev']['toxic'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert words to vector with Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# extract 2-grams of words in addition to the 1-grams\n",
    "vectorizer = CountVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "feature_train = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighten important words by using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Tfâ€“idf term weighting\n",
    "transformer = TfidfTransformer(norm='l2')\n",
    "feature_train = transformer.fit_transform(feature_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "index = np.argsort(feature_train[0])[::-1]\n",
    "feature_words = feature_names[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- original comment ---\")\n",
    "print(X_train[0])\n",
    "\n",
    "print(\"\\n---- top 10 features ---\")\n",
    "print(feature_words[:10])\n",
    "\n",
    "print(\"\\n--- label ---\")\n",
    "print(Y_train[0])\n",
    "\n",
    "print(\"\\n---- vectorized comment ---\")\n",
    "print(feature_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: Train Classifier using TF-IDF features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf1 = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features=10000, ngram_range=(1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm='l2')),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "\n",
    "clf1 = clf1.fit(X_train, Y_train)\n",
    "\n",
    "# evaluate model\n",
    "print(\"[{}] Accuracy: train = {}, test = {}\".format(\n",
    "        clf1.__class__.__name__,\n",
    "        clf1.score(X_train, Y_train),\n",
    "        clf1.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, clf1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-Boosted Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf2 = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features=10000, ngram_range=(1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm='l2')),\n",
    "    ('clf', GradientBoostingClassifier(n_estimators=10, verbose=1)),\n",
    "])\n",
    "\n",
    "clf2 = clf2.fit(X_train, Y_train)\n",
    "\n",
    "# evaluate model\n",
    "print(\"[{}] Accuracy: train = {}, test = {}\".format(\n",
    "        clf2.__class__.__name__,\n",
    "        clf2.score(X_train, Y_train),\n",
    "        clf2.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, clf2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4: Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correctly classify nice comment\n",
    "clf1.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correctly classify nasty comment\n",
    "clf1.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "# save model for deployment\n",
    "joblib.dump(clf1, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
